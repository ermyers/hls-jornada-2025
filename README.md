# hls-jornada-2025
2025 updated code for downloading HLS imagery over the Jornada Experimental Range and extracting time-series information at eddy covariance tower locations.

Previous code (used for https://spj.science.org/doi/10.34133/remotesensing.0190) remains available on figshare:
https://figshare.com/collections/Novel_use_of_image_time_series_to_distinguish_dryland_vegetation_responses_to_wet_and_dry_years/6830721

For more information on the HLS v2.0 data product, you can read the HLS_User_Guide_V2, uploaded as a PDF to this repository.

## To download HLS imagery
Follow the setup instructions at https://github.com/nasa/HLS-Data-Resources/tree/main/bash/hls-bulk-download

You will need a NASA Earthdata login, a netrc file with your Earthdata login information, the getHLS.sh script (already included in this repository), and a Bash shell to run the getHLS.sh script. You will also need a text file with the tile or tiles of interest (already included in this repository as tileid.txt; tile 13SCS covers the area over all Jornada phenocams) and a destination folder for downloaded imagery (I recommend creating an imagery folder in your project directory).

In your bash shell, navigate to the folder containing the getHLS.sh script. From there, a command to download all L30 and S30 v2.0 images for the 13SCS tile collected between 1 August 2023 and 1 January 2024 to the imagery folder might look like:

```./getHLS.sh tileid.txt 2023-09-01 2024-01-01 imagery```

## To extract phenocam pixel data from HLS imagery
Extracted values for jergrassland2, jernovel2, and jershrubland2 for images collected between January 2021 and May 2025 are already saved in the outputs/ec_locations2021-2025 folder as CSV files. If you wish to run the code yourself or understand how it works, you can read below.

import_hls_pixel_data_2025.ipynb is designed to extract the 3x3 grid of 30-m pixels centered around a Jornada phenocam of choice (specified by the "phenocam" variable) from downloaded HLS images. For the specified phenocam, the the code records when each image was collected (Year and DOY), the satellite product (L30 or S30), the phenocam (Phenocam), whether the 3x3 grid of pixels was centered around the phenocam (phenocam located in the center pixel of the 3x3 grid) or north of the phenocam (phenocam located in the bottom row, middle column of the 3x3 grid), and mean and standard deviation values for each of the spectral bands. Outputs are saved as CSV files.

This code runs in JupyterLab and requires some setup before it will run. You will need to create a Python environment (I recommend using conda) and install rasterio, numpy, and pandas. You will then need to make your new Python environment available as a Jupyter kernel, and select this kernel in JupyterLab. More on Python environment and Jupyter kernel creation here: https://scinet.usda.gov/guides/ide/jupyter#create-python-environments-and-jupyter-kernels

When running the code, you should change the value of "phenocam" in the third code block to your desired phenocam name to get outputs for a specific phenocam.

## To clean the extracted pixel data and calculate vegetation indices
clean_hls_data.R combines all phenocams into a single dataframe, calculates vegetation indices (EVI, NDVI, and GCC) from mean band values, and removes high aerosol and cloud-contaminated images from the time-series.

Cleaned HLS data are saved under outputs/hls_v20_ec_towers_clean.RData

## To smooth and expand the cleaned data
smooth_hls_data.R performs LOESS smoothing with a span of 0.03 on cleaned HLS data to create daily, smoothed EVI and GCC time series.

Outputs are hls_data (identical to the cleaned HLS data generated by clean_hls_data.R) and hls_smooth_data (smoothed daily EVI and GCC). Outputs are saved in two formats: as R dataframes (outputs/hls_ec_towers_smoothed.RData) and as CSV files (hls_data: outputs/hls_ec_towers.csv; hls_smooth_data: outputs/hls_ec_towers_smoothed.csv).
